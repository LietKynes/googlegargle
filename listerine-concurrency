#!/bin/bash
# ./listerine-concurrency fork
# This version runs googlegargle in parallel for situations like mine where I'm throttled at 80k per download, but I can have several in parallel. I don't know if google or my ISP does the throttling.
# By default this script runs 3 processes in parallel, but you can adjust the number in real-time like this:
# echo 30 > _max_concurrent
# To stop the script safely you should do this:
# echo 0 > _max_concurrent
#
#./listerine - a companion to the google gargle project
#relies on googlegrape, aria2c, curl, and youtube-dl

SERVER=199.48.254.90:8081
GARGLE=./googlegargle

while getopts :u: OPT; do
    case $OPT in
	u)
	    USERNAME="$OPTARG"
	    ;;
	*)
	    echo "usage: `basename $0` [-u USERNAME]"
            exit 1;
    esac
done

warning() {
  echo "$0: $*" >&2
}

error() {
  echo "$0: $*" >&2
  exit 2
}

if [ -f _username ]; then
    read USERNAME < _username
fi

if [ -z $USERNAME ]; then
    error "You must supply a username with the -u option before you can begin"
fi

if [ ! -f $GARGLE ]; then
    error "Couldn't find googlegargle. Are you sure you cloned everything from the git repository?"
    exit 2
fi

EXTERN_IP=`curl --silent ipv4.icanhazip.com` #Do not change without good reason, or underscor will eat your brains
RAN=0 #how many processes ran so far

askserver() {
    cmd="$1"
    shift
    rest=
    for chunk in "$@"; do
        rest="$rest/$chunk"
    done
    if ! curl --silent --fail "http://$SERVER/$cmd/${USERNAME}$rest"; then
        error "Couldn't contact the listerine server. The listerine server could be down, or your network."
    fi
}

askserver introduce $EXTERN_IP

mkdir -p _logs
QUEUE_DIR=_queue-$$
trap "rm -rf $QUEUE_DIR" 0
mkdir -p $QUEUE_DIR
for PID in $(ls $QUEUE_DIR); do
    echo "Please clean up $QUEUE_DIR/"
    exit 1
done
RUNNING=0
MAX=1
while [ $MAX -gt 0 -o $RUNNING -gt 0 ]; do
    if [ -f ./_max_concurrent ]; then
        read MAX < ./_max_concurrent
    else
        MAX=1
    fi
    RUNNING=0
    for PID in $(jobs -p); do
        if kill -0 "$PID" 2>/dev/null; then
            let "RUNNING = $RUNNING + 1"
        fi
    done
    echo -n "There are $RUNNING running jobs (limit $MAX). PIDs:"
    for PID in $(ls $QUEUE_DIR/); do
        echo -n " $PID"
    done
    if [ $MAX -eq 0 ]; then
        echo -n ". Limit is 0, will exit when these jobs end"
    fi
    while [ $RUNNING -lt $MAX ]; do
	echo
  echo "Getting an id from $SERVER, authenticated as $USERNAME with IP $EXTERN_IP"
  id=`askserver getID | sed "s/[^0-9\\-]//g"`
  if [ -z $id ]; then
    error "The server didn't give us an id. This could mean the server is broken, or possibly that we're finished."
  fi

  echo ID is $id

  $GARGLE -- "$id" 1>>_logs/"$id".log 2>&1 &
        echo $id > $QUEUE_DIR/$!
        echo "googlegargle started for $id with PID $!"
        let "RAN = $RAN + 1"
        let "RUNNING = $RUNNING + 1"
    done
    for PID in $(ls $QUEUE_DIR/); do
        read id < $QUEUE_DIR/"$PID"
        if kill -0 "$PID" 2>/dev/null; then
            echo -n "googlegargle status for $id: 	"
            tail -n1 _logs/"$id".log
            continue
        fi
  SEPDIB=$(echo "$id" | sed 's/-//g' | cut -c1)
  SECDIB=$(echo "$id" | sed 's/-//g' | cut -c2)
  THIRDIB=$(echo "$id" | sed 's/-//g' | cut -c3)
  file="$SEPDIB/$SECDIB/$THIRDIB/$id/$id.flv"
  if [ -f $file -a ! -f "$SEPDIB/$SECDIB/$THIRDIB/$id/$id.flv.aria2" ]; then
    hash=`sha1sum "$file"|awk '{print $1}'`
    size=`du -b "$file"|awk '{print $1}'`
    echo "Hash is $hash"
    echo "ID is $id"
    echo "USERNAME is $USERNAME"
    echo "Size is $size"
    askserver finishVid $id $size $hash
  else
    warning "Failed to download anything for $id."
  fi
    done

  if [ -f STOP ]; then 
    echo "$0: I see a file called STOP. Stopping."
    exit 0
  fi
  echo .
  sleep 5
done
echo "Ran a total of $RAN downloads."
